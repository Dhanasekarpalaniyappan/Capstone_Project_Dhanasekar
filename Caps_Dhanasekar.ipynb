{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25153940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06b9f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed43187",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"read hive\").enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "909e2293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|      namespace|\n",
      "+---------------+\n",
      "|  07172021_nyse|\n",
      "|07172021_retail|\n",
      "|   07172021_sms|\n",
      "|    1230_trendy|\n",
      "|1230_trendytech|\n",
      "|  1540retail_db|\n",
      "|           1src|\n",
      "|          26may|\n",
      "|           2stg|\n",
      "|           3etl|\n",
      "|           4tmp|\n",
      "|       596_test|\n",
      "|    596_testing|\n",
      "|          5core|\n",
      "|            7up|\n",
      "|  967_retail_db|\n",
      "|   988_chapter0|\n",
      "|          _nyse|\n",
      "|        _retail|\n",
      "|       _retails|\n",
      "+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.sql(\"show databases\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb4736c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.sql(\"use capsdhana\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3193354c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e760445f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>database</th><th>tableName</th><th>isTemporary</th></tr>\n",
       "<tr><td>capsdhana</td><td>details</td><td>false</td></tr>\n",
       "<tr><td>capsdhana</td><td>detailspart</td><td>false</td></tr>\n",
       "<tr><td>capsdhana</td><td>status</td><td>false</td></tr>\n",
       "<tr><td>capsdhana</td><td>statusbucket</td><td>false</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+------------+-----------+\n",
       "| database|   tableName|isTemporary|\n",
       "+---------+------------+-----------+\n",
       "|capsdhana|     details|      false|\n",
       "|capsdhana| detailspart|      false|\n",
       "|capsdhana|      status|      false|\n",
       "|capsdhana|statusbucket|      false|\n",
       "+---------+------------+-----------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=spark.sql(\"show tables\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92b0ca98",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+----------+--------------------+\n",
      "|courseid|               title|          competency|complexity|          coursetype|\n",
      "+--------+--------------------+--------------------+----------+--------------------+\n",
      "|   C0001|Certificate in Cl...|           Technical|     Basic|               Cloud|\n",
      "|   C0002|Certificate in Vi...|           Technical|     Basic|               Cloud|\n",
      "|   C0003|\"Diploma in Infor...| Networking and C...|  Security|               Cloud|\n",
      "|   C0004|BE (Hons) in CSE ...|              Domain|  Advanced|               Cloud|\n",
      "|   C0005|BTech in Computer...|              Domain|  Advanced|               Cloud|\n",
      "|   C0006|BTech in Computer...|              Domain|  Advanced|               Cloud|\n",
      "|   C0007|BCA with Microsof...|            Security|  Advanced|               Cloud|\n",
      "|   C0008|BTech in Informat...|           Technical|  Advanced|               Cloud|\n",
      "|   C0009|MCA with speciali...|           Technical|  Advanced|               Cloud|\n",
      "|   C0010|ME in Cloud Compu...|           Technical|     Basic|               Cloud|\n",
      "|   C0011|MTech Computer Sc...|           Technical|     Basic|               Cloud|\n",
      "|   C0012|Bachelor’s in Com...|              Domain|     Basic|Hardware and Netw...|\n",
      "|   C0013|B.Sc in Hardware ...|              Domain|  Advanced|Hardware and Netw...|\n",
      "|   C0014|BTech in IT and N...|              Domain|     Basic|Hardware and Netw...|\n",
      "|   C0015|BS in Hardware an...|              Domain|     Basic|Hardware and Netw...|\n",
      "|   C0016|BSc in Networking...|              Domain|     Basic|Hardware and Netw...|\n",
      "|   C0017|M.Tech in Network...|              Domain|  Advanced|Hardware and Netw...|\n",
      "|   C0018|M.Sc in Hardware ...|              Domain|  Advanced|Hardware and Netw...|\n",
      "|   C0019|MSc in Wireless N...|              Domain|  Advanced|Hardware and Netw...|\n",
      "|   C0020|Diploma in Comput...|              Domain|  Advanced|Hardware and Netw...|\n",
      "+--------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "details=spark.sql(\"select * from detailspart\")\n",
    "details.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76fc7d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+--------------+-----+-------------+\n",
      "|studentsid|courseid| examdate|attendedstatus|marks|       result|\n",
      "+----------+--------+---------+--------------+-----+-------------+\n",
      "|     S0151|   C0010|26 Feb 19|        Absent|    0|Not Qualified|\n",
      "|     S0300|   C0010|26 Feb 19|        Absent|    0|Not Qualified|\n",
      "|     S0264|   C0006|22 Feb 19|        Absent|    0|Not Qualified|\n",
      "|     S0148|   C0007|23 Feb 19|        Absent|    0|Not Qualified|\n",
      "|     S0147|   C0006|22 Feb 19|        Absent|    0|Not Qualified|\n",
      "|     S0146|   C0005|21 Feb 19|        Absent|    0|Not Qualified|\n",
      "|     S0084|   C0015| 3 Mar 19|        Absent|    0|Not Qualified|\n",
      "|     S0263|   C0005|21 Feb 19|        Absent|    0|Not Qualified|\n",
      "|     S0143|   C0002|18 Feb 19|        Absent|    0|Not Qualified|\n",
      "|     S0023|   C0023|28 Feb 19|        Absent|    0|Not Qualified|\n",
      "|     S0141|   C0017| 5 Mar 19|        Absent|    0|Not Qualified|\n",
      "|     S0140|   C0016| 4 Mar 19|        Absent|    0|Not Qualified|\n",
      "|     S0139|   C0015| 3 Mar 19|        Absent|    0|Not Qualified|\n",
      "|     S0138|   C0014| 2 Mar 19|        Absent|    0|Not Qualified|\n",
      "|     S0085|   C0016| 4 Mar 19|        Absent|    0|Not Qualified|\n",
      "|     S0136|   C0017| 5 Mar 19|        Absent|    0|Not Qualified|\n",
      "|     S0135|   C0016| 4 Mar 19|        Absent|    0|Not Qualified|\n",
      "|     S0134|   C0015| 3 Mar 19|        Absent|    0|Not Qualified|\n",
      "|     S0133|   C0014| 2 Mar 19|        Absent|    0|Not Qualified|\n",
      "|     S0086|   C0017| 5 Mar 19|        Absent|    0|Not Qualified|\n",
      "+----------+--------+---------+--------------+-----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status=spark.sql(\"select * from statusbucket\")\n",
    "status.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c820db3a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- courseid: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- competency: string (nullable = true)\n",
      " |-- complexity: string (nullable = true)\n",
      " |-- coursetype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "details.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25fb5ffb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- studentsid: string (nullable = true)\n",
      " |-- courseid: string (nullable = true)\n",
      " |-- examdate: string (nullable = true)\n",
      " |-- attendedstatus: string (nullable = true)\n",
      " |-- marks: integer (nullable = true)\n",
      " |-- result: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0e2a27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|       result|count|\n",
      "+-------------+-----+\n",
      "|Not Qualified|  149|\n",
      "|    Qualified|  151|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_count = status.groupBy(\"result\").count().show()\n",
    "results_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7e15f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absent_count=status.select('attendedstatus').where(status.attendedstatus=='Absent').count()\n",
    "absent_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc833340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+--------+\n",
      "|          avg_mark|min_mark|max_mark|\n",
      "+------------------+--------+--------+\n",
      "|40.013333333333335|       0|      92|\n",
      "+------------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mark_summary =(status.agg\n",
    "                   (\n",
    "                    F.avg(F.col('marks')).alias('avg_mark'),\n",
    "                    F.min(F.col('marks')).alias('min_mark'),\n",
    "                    F.max(F.col('marks')).alias('max_mark')\n",
    "                    )\n",
    "                .show()\n",
    "                )\n",
    "mark_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
